{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baccc8ba-6dff-4282-bf49-b1085d1966ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from olmo.config import (\n",
    "    CheckpointType,\n",
    "    DDPGradSyncMode,\n",
    "    DistributedStrategy,\n",
    "    TrainConfig,\n",
    ")\n",
    "import torch\n",
    "from olmo.model import OLMo\n",
    "from olmo.data import build_train_dataloader\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from olmo.model import LayerNorm, RMSLayerNorm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796d52fc-ba82-4a2e-9215-ecf03c782c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"/n/holylfs06/LABS/sham_lab/Lab/ameterez/OLMo\"\n",
    "os.environ['CHECKPOINTS_PATH'] = '/n/netscratch/kempner_sham_lab/Everyone/ameterez/150m_1_chinchilla_1_repeat'\n",
    "\n",
    "save_path = \"/n/netscratch/kempner_sham_lab/Everyone/ameterez/layernorm_plots\"\n",
    "job_number = \"28012014_10\"\n",
    "\n",
    "job_path = f\"{save_path}/{job_number}\"\n",
    "if not os.path.exists(job_path):\n",
    "    os.mkdir(job_path)\n",
    "\n",
    "exp_path = f\"{os.environ['CHECKPOINTS_PATH']}/{job_number}\"\n",
    "import re\n",
    "\n",
    "def get_unsharded_steps(names):\n",
    "    \"\"\"Return all 'step<N>-unsharded' entries sorted by N (numeric).\"\"\"\n",
    "    pairs = []\n",
    "    for s in names:\n",
    "        m = re.fullmatch(r\"step(\\d+)-unsharded\", s)\n",
    "        if m:\n",
    "            pairs.append((int(m.group(1)), s))\n",
    "    return [s for _, s in sorted(pairs)]\n",
    "\n",
    "steps_saved = get_unsharded_steps(os.listdir(f\"{os.environ['CHECKPOINTS_PATH']}/26955159_4/\"))\n",
    "\n",
    "class LNDenominatorRecorder:\n",
    "    \"\"\"\n",
    "    Attach forward hooks to all torch.nn.LayerNorm modules in `model`.\n",
    "    On each forward, saves sqrt(Var(x) + eps) computed over the LayerNorm's normalized dims.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, layernorm_type: str):\n",
    "        self.model = model\n",
    "\n",
    "        self.step = 0\n",
    "        self.cache: Dict[str, List[torch.Tensor]] = defaultdict(list)\n",
    "        self._handles: List[torch.utils.hooks.RemovableHandle] = []\n",
    "        self.layernorm_type = layernorm_type\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, LayerNorm) or isinstance(module, RMSLayerNorm):\n",
    "                h = module.register_forward_hook(self._make_hook(name, module))\n",
    "                self._handles.append(h)\n",
    "\n",
    "    def _make_hook(self, name: str, module):\n",
    "        eps = float(module.eps)\n",
    "        norm_ndims = len(module.normalized_shape)\n",
    "        safe_name = name.replace(\".\", \"_\")\n",
    "\n",
    "        def hook(_mod, inputs, _output):\n",
    "            x = inputs[0]\n",
    "            x_f = x.detach().float()\n",
    "            if self.layernorm_type == 'layernorm':\n",
    "                dims = tuple(range(x_f.ndim - norm_ndims, x_f.ndim))\n",
    "                mean = x_f.mean(dim=dims, keepdim=True)\n",
    "                var  = (x_f - mean).pow(2).mean(dim=dims, keepdim=True) \n",
    "                denom = torch.rsqrt(var + eps)\n",
    "            elif self.layernorm_type == 'rms':\n",
    "                x32 = x.detach().to(torch.float32)\n",
    "                variance = x32.pow(2).mean(dim=-1, keepdim=True)\n",
    "                denom = torch.sqrt(variance + eps)  # shape [B, S, 1]\n",
    "            else:\n",
    "                print(\"No such norm!\")\n",
    "            to_save = denom.cpu().squeeze()\n",
    "            self.cache[name] = to_save\n",
    "\n",
    "        return hook\n",
    "\n",
    "    def next_step(self):\n",
    "        self.step += 1\n",
    "\n",
    "    def close(self):\n",
    "        for h in self._handles:\n",
    "            h.remove()\n",
    "        self._handles.clear()\n",
    "\n",
    "\n",
    "# fix some batch of data \n",
    "batch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb28934e-c13b-4fea-a4b7-f49709eb8568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step100-unsharded\n",
      "step200-unsharded\n",
      "step300-unsharded\n",
      "step400-unsharded\n",
      "step500-unsharded\n",
      "step600-unsharded\n",
      "step700-unsharded\n",
      "step800-unsharded\n",
      "step900-unsharded\n",
      "step1000-unsharded\n",
      "step1100-unsharded\n",
      "step1200-unsharded\n",
      "step1400-unsharded\n",
      "step1500-unsharded\n",
      "step1700-unsharded\n",
      "step1900-unsharded\n",
      "step2100-unsharded\n",
      "step2300-unsharded\n",
      "step2500-unsharded\n",
      "step2800-unsharded\n",
      "step3100-unsharded\n",
      "step3800-unsharded\n",
      "step4200-unsharded\n",
      "step4600-unsharded\n",
      "step5100-unsharded\n",
      "step5600-unsharded\n",
      "step6200-unsharded\n",
      "step6900-unsharded\n",
      "step7600-unsharded\n",
      "step8400-unsharded\n",
      "step9200-unsharded\n",
      "step10200-unsharded\n",
      "step11300-unsharded\n",
      "step12500-unsharded\n"
     ]
    }
   ],
   "source": [
    "for step in steps_saved:\n",
    "    print(step)\n",
    "    ckpt_path = f\"{exp_path}/{step}/\"\n",
    "    config_path = f\"{ckpt_path}/config.yaml\"\n",
    "    weights_path = f\"{ckpt_path}/model.pt\"\n",
    "    \n",
    "    cfg = TrainConfig.load(config_path)\n",
    "    cfg.data.num_workers = 1\n",
    "    olmo_model = OLMo(cfg.model)\n",
    "\n",
    "    olmo_model.load_state_dict(torch.load(weights_path, weights_only=True), assign=True)\n",
    "    olmo_model = olmo_model.to('cuda:0')\n",
    "\n",
    "    if batch is None: # just get once\n",
    "        train_loader = build_train_dataloader(cfg)\n",
    "        iterator = iter(train_loader)\n",
    "        batch = next(iterator)\n",
    "        input_ids = batch['input_ids'].to('cuda:0')\n",
    "\n",
    "    rec = LNDenominatorRecorder(olmo_model, 'rms') \n",
    "    with torch.no_grad():\n",
    "        olmo_model(input_ids)\n",
    "        rec.next_step()\n",
    "    rec.close()\n",
    "    del olmo_model\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(7, 8, figsize=(18,14))\n",
    "    keys = list(rec.cache.keys())\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx == len(keys):\n",
    "            break\n",
    "        key = keys[idx]\n",
    "        data = rec.cache[key].flatten().numpy()\n",
    "        ax.hist(data, bins=200, density=True, alpha=0.6)\n",
    "        plot_title = '_'.join(key.split('.')[1:])\n",
    "        ax.set_title(plot_title, fontsize=8)\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "    fig.suptitle(step)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{job_path}/{step}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e11708-539b-4a74-acb3-3d443c9fe659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
